{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test, mean_train, std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot = OneHotEncoder()\n",
    "y_train = one_hot.fit_transform(y_train).toarray()\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        12816     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 136,966\n",
      "Trainable params: 136,774\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#卷積組合 \n",
    "classifier.add(Convolution2D(64, kernel_size=(3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation('sigmoid'))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(16, kernel_size=(5, 5), padding='same'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim = 100, activation='relu'))\n",
    "               \n",
    "#輸出\n",
    "classifier.add(Dense(output_dim = 10, activation='softmax'))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 1.3867 - acc: 0.5109\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.9711 - acc: 0.6598\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.8174 - acc: 0.7155\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 0.7269 - acc: 0.7454\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.6436 - acc: 0.7731\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.5764 - acc: 0.7974\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.5145 - acc: 0.8208\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.4551 - acc: 0.8404\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.3995 - acc: 0.8586\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 0.3521 - acc: 0.8760\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.3043 - acc: 0.8916\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.2673 - acc: 0.9056\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.2384 - acc: 0.9160\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.2045 - acc: 0.9269\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 0.1855 - acc: 0.9342\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.1682 - acc: 0.9399\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1460 - acc: 0.9483\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1384 - acc: 0.9515\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.1394 - acc: 0.9513\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1119 - acc: 0.9605\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1185 - acc: 0.9584\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1039 - acc: 0.9635\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1001 - acc: 0.9649\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0905 - acc: 0.9682\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.1004 - acc: 0.9644\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0924 - acc: 0.9676\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0903 - acc: 0.9683\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0827 - acc: 0.9709\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0736 - acc: 0.9750\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0877 - acc: 0.9701\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0837 - acc: 0.9716\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0638 - acc: 0.9771\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0689 - acc: 0.9763\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0694 - acc: 0.9772\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0801 - acc: 0.9729\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0698 - acc: 0.9764\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.0593 - acc: 0.9804\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0624 - acc: 0.9795\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0726 - acc: 0.9751\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0656 - acc: 0.9778\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0581 - acc: 0.9800\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0517 - acc: 0.9826\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0521 - acc: 0.9824\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0681 - acc: 0.9770\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0723 - acc: 0.9754\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.0447 - acc: 0.9847\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0459 - acc: 0.9842\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0553 - acc: 0.9814\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0493 - acc: 0.9833\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 196s 4ms/step - loss: 0.0544 - acc: 0.9826\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 0.0572 - acc: 0.9808\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 3597s 72ms/step - loss: 0.0601 - acc: 0.9805\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 20856s 417ms/step - loss: 0.0447 - acc: 0.9851\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 11888s 238ms/step - loss: 0.0475 - acc: 0.9839\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0440 - acc: 0.9853\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 222s 4ms/step - loss: 0.0600 - acc: 0.9809\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0558 - acc: 0.9826\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0414 - acc: 0.9862\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 231s 5ms/step - loss: 0.0471 - acc: 0.9843\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 224s 4ms/step - loss: 0.0481 - acc: 0.9846\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 195s 4ms/step - loss: 0.0462 - acc: 0.9849\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 217s 4ms/step - loss: 0.0391 - acc: 0.9873\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.0426 - acc: 0.9863\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0539 - acc: 0.9834\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 221s 4ms/step - loss: 0.0498 - acc: 0.9843\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.0387 - acc: 0.9874\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 205s 4ms/step - loss: 0.0428 - acc: 0.9866\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0459 - acc: 0.9855\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0397 - acc: 0.9875\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 199s 4ms/step - loss: 0.0373 - acc: 0.9882\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0438 - acc: 0.9863\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 203s 4ms/step - loss: 0.0410 - acc: 0.9867\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 199s 4ms/step - loss: 0.0335 - acc: 0.9889\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 207s 4ms/step - loss: 0.0379 - acc: 0.9878\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0538 - acc: 0.9834\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 222s 4ms/step - loss: 0.0454 - acc: 0.9858\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 205s 4ms/step - loss: 0.0347 - acc: 0.9888\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0358 - acc: 0.9884\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 0.0297 - acc: 0.9909\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0354 - acc: 0.9894\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 203s 4ms/step - loss: 0.0480 - acc: 0.9858\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0377 - acc: 0.9880\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0343 - acc: 0.9897\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0309 - acc: 0.9902\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 200s 4ms/step - loss: 0.0306 - acc: 0.9901\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 207s 4ms/step - loss: 0.0443 - acc: 0.9862\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0402 - acc: 0.9872\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 202s 4ms/step - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.0382 - acc: 0.9884\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 235s 5ms/step - loss: 0.0276 - acc: 0.9918\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 218s 4ms/step - loss: 0.0312 - acc: 0.9906\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 208s 4ms/step - loss: 0.0404 - acc: 0.9882\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0416 - acc: 0.9877\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 198s 4ms/step - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.0307 - acc: 0.9903\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 204s 4ms/step - loss: 0.0334 - acc: 0.9899\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 201s 4ms/step - loss: 0.0380 - acc: 0.9885\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.0349 - acc: 0.9893\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 197s 4ms/step - loss: 0.0259 - acc: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4b6a9450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train, y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.3718694e-09, 9.9227411e-25, 8.0547119e-07, 9.9999630e-01,\n",
       "        2.0868081e-06, 1.2787728e-12, 1.6190929e-13, 3.1187218e-14,\n",
       "        7.8865298e-07, 3.2949112e-15]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
